{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M01 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Summary\n",
    "This is a Notebook showing how to build OOP Linear Rgeression Model inspired by scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "np.random.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Design ABC\n",
    "Since I'm writing ML models both with:\n",
    "1. an eye to build more generalized models\n",
    "2. influence from scikit-learn\n",
    "\n",
    "I will opt to use a consolidated metaclass `BaseEstimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEstimator(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self, normalize=False):\n",
    "        self._normalize = normalize\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self, design_matrix, labels):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, design_matrix):\n",
    "        pass\n",
    "    \n",
    "    def score(self, design_matrix, labels):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_params(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def set_params(self, params):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Create support Metrics class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(design_matrix, labels):\n",
    "        \"\"\"Performs min-max normalization on all columns of data\n",
    "        y -> (y -  min(y)) / (max(y) - min(y))\n",
    "        ---------\n",
    "        Arguments:\n",
    "        @design_matrix: 1D or 2D numpy array \n",
    "        @labels: 1D numpy array        \n",
    "        ______\n",
    "        Return: 2-tuple (X, y)\n",
    "        \"\"\"        \n",
    "        print(f'Running normalize')\n",
    "        return design_matrix, labels\n",
    "    \n",
    "    def _residuals(self, design_matrix, labels):\n",
    "        \"\"\"Transforms data & labels into residuals\n",
    "        (X, y) -> y - h(θ; X, y)        \n",
    "        ---------\n",
    "        Arguments:\n",
    "        @design_matrix: 1D or 2D numpy array \n",
    "        @labels: 1D numpy array        \n",
    "        ______\n",
    "        Return: 1D numpy array (same shape as labels)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return labels - self.predict(design_matrix)\n",
    "        except AttributeError:\n",
    "            return np.zeros(labels.shape)\n",
    "        \n",
    "    def _mse(self, design_matrix, labels):\n",
    "        \"\"\"Computes Mean Squared Error of data & labels\n",
    "        (X, y) -> ∑ (y - h(θ; X, y))^2 / n\n",
    "        ---------\n",
    "        Arguments:\n",
    "        @design_matrix: 1D or 2D numpy array \n",
    "        @labels: 1D numpy array        \n",
    "        ______\n",
    "        Return: Non-negative Float\n",
    "        \"\"\"\n",
    "        residuals_ = self._residuals(design_matrix, labels)\n",
    "        return np.mean(residuals_ ** 2)\n",
    "    \n",
    "    def _mxe(self, design_matrix, labels):\n",
    "        \"\"\"Computes Mean Cross Entropy of data & labels\n",
    "        (X, y) -> -∑ (y * log(h(θ; X, y)) + (1 - y) * log(1 - h(θ; X, y))) / n\n",
    "        ---------\n",
    "        Arguments:\n",
    "        @design_matrix: 1D or 2D numpy array \n",
    "        @labels: 1D numpy array        \n",
    "        ______\n",
    "        Return: Non-negative Float\n",
    "        \"\"\"\n",
    "        predictions = self.predict(design_matrix)\n",
    "        cross_entropy = lambda y, y_: np.log(y_) if y == 1 else np.log(1 - y_)\n",
    "        cross_entropies = [cross_entropy(y, y_) for y, y_ in zip(labels, predictions)]\n",
    "        return -np.mean(cross_entropies)\n",
    "\n",
    "    def _gradient(self, design_matrix, labels):\n",
    "        \"\"\"Computes Gradient of cost function\n",
    "        (X, y) -> ∇J(θ; X, y)\n",
    "        ---------\n",
    "        Arguments:\n",
    "        @design_matrix: 1D or 2D numpy array \n",
    "        @labels: 1D numpy array        \n",
    "        ______\n",
    "        Return: 1D numpy array (same shape as model coefficients)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _gradient_descent(self, design_matrix, labels, cost_func, cost_threshold=1e-5, learn_rate=.05):\n",
    "        \"\"\"Performs gradient descent\n",
    "        1. Initialize random array of coefficients\n",
    "        2. Initialize delta_cost\n",
    "        3. Loop and perform gradient descent\n",
    "        ---------\n",
    "        Arguments:\n",
    "        @design_matrix: 1D or 2D numpy array\n",
    "        @labels: 1D numpy array\n",
    "        @cost_func: function that takes 2 positional arguments\n",
    "        \n",
    "        Keyword Arguments:\n",
    "        @cost_threshold (default=1e-5)\n",
    "        @learn_rate (default=.05)\n",
    "        ______\n",
    "        Return: None\n",
    "        \"\"\"\n",
    "        rand_array = np.random.rand(design_matrix.shape[1] + self._fit_intercept)\n",
    "        self.set_params(rand_array)\n",
    "        \n",
    "        delta_cost = 1\n",
    "        cost = cost_func(design_matrix, labels)\n",
    "        self._cost_sequence = [cost]\n",
    "        while delta_cost > cost_threshold:\n",
    "            old_cost = cost\n",
    "            new_params = self.get_params() - learn_rate * self._gradient(design_matrix, labels)\n",
    "            self.set_params(new_params)\n",
    "            cost = cost_func(design_matrix, labels)\n",
    "            self._cost_sequence.append(cost)\n",
    "            delta_cost = cost - old_cost\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V. Defining the Linear Regression Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(BaseEstimator, Metrics):\n",
    "    def __init__(self, fit_intercept=True, normalize=False):\n",
    "        super().__init__(normalize=normalize)\n",
    "        self._fit_intercept = fit_intercept\n",
    "        \n",
    "    def _prepend_ones(self, design_matrix):\n",
    "        ones_array = np.ones(design_matrix.shape[0])\n",
    "        if self._fit_intercept:\n",
    "            return np.insert(design_matrix, 0, ones_array, axis=1)\n",
    "        return design_matrix\n",
    "    \n",
    "    def _gradient(self, design_matrix, labels):\n",
    "        X = self._prepend_ones(design_matrix)\n",
    "        residuals_ = self._residuals(design_matrix, labels)\n",
    "        return (-2 / X.shape[0]) * np.dot(X.T, residuals_)\n",
    "    \n",
    "    def fit(self, design_matrix, labels):\n",
    "        X, y = type(self).normalize(design_matrix, labels)\n",
    "        self._gradient_descent(X, y, self._mse)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, design_matrix):\n",
    "        X = self._prepend_ones(design_matrix)\n",
    "        return np.dot(X, self.get_params())\n",
    "    \n",
    "    def score(self, design_matrix, labels):\n",
    "        r_squared_ = 1 - self._mse(design_matrix, labels) / np.var(labels)\n",
    "        return r_squared_\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.coefs_\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.coefs_ = params\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI. Testing the class and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup sample/random data\n",
    "sample_size = 1000\n",
    "num_features = 6\n",
    "X = np.around(np.random.rand(sample_size * num_features).reshape(sample_size, num_features) * 100, 2)\n",
    "y = np.around(np.random.rand(sample_size) * 100, 2)\n",
    "\n",
    "X = np.array([[1, 3], [-3, 3], [4, 5], [2, 3], [-1, 7], [8, 9]])\n",
    "y = np.array([1, 2, 4, 2, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running normalize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivekjha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: RuntimeWarning: overflow encountered in square\n",
      "/Users/vivekjha/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:75: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "/Users/vivekjha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.78492582e+152, 2.60275155e+153, 4.29754191e+153])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X, y)\n",
    "reg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VII. Extending to Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(LinearRegression):\n",
    "    def __init__(self, fit_intercept=True, normalize=False):\n",
    "        super().__init__(fit_intercept=fit_intercept, normalize=normalize)\n",
    "        \n",
    "    def _gradient(self, design_matrix, labels):\n",
    "        return super()._gradient(design_matrix, labels) / 2\n",
    "        \n",
    "    def fit(self, design_matrix, labels):\n",
    "        X, y = type(self).normalize(design_matrix, labels)\n",
    "        self._gradient_descent(X, y, self._mxe)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, design_matrix):\n",
    "        predictions = super().predict(design_matrix)\n",
    "        sigmoid = lambda t: 1 / (1 + np.exp(-t))\n",
    "        return sigmoid(predictions)\n",
    "    \n",
    "    def score(self, design_matrix, labels):\n",
    "        return self._mxe(design_matrix, labels)\n",
    "        \n",
    "    def classify(self, design_matrix, decision_boundary=0.5):\n",
    "        predictions = self.predict(design_matrix)\n",
    "        classifications = [int(prediction >= decision_boundary) for prediction in predictions]\n",
    "        return np.array(classifications)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running normalize\n",
      "[2.391177164987745, 1.9499917680701901]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1, 0, 1, 1, 0, 0])\n",
    "clf = LogisticRegression().fit(X, y)\n",
    "print(clf._cost_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
